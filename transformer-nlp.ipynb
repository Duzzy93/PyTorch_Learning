{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install \"numpy==1.24.4\" --force-reinstall --no-cache-dir\n# !pip install \"scipy==1.10.1\" --force-reinstall --no-cache-dir\n# !pip install \"torch==2.1.0\" --force-reinstall --no-cache-dir\n# !pip install \"torchvision==0.16.0\" --force-reinstall --no-cache-dir\n# !pip install \"torchtext==0.15.2\" --force-reinstall --no-cache-dir\n# !pip install \"spacy==3.7.2\" --force-reinstall --no-cache-dir\n# !python -m spacy download ko_core_news_sm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T06:29:00.601491Z","iopub.execute_input":"2025-07-09T06:29:00.601755Z","iopub.status.idle":"2025-07-09T06:29:00.607083Z","shell.execute_reply.started":"2025-07-09T06:29:00.601727Z","shell.execute_reply":"2025-07-09T06:29:00.606400Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport math\nimport pandas as pd\nfrom tqdm import tqdm\nfrom timeit import default_timer as timer\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn, optim\nfrom torchinfo import summary\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torchtext.data.utils import get_tokenizer\nfrom torch.nn.utils.rnn import pad_sequence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:18.516394Z","iopub.execute_input":"2025-07-09T05:35:18.517089Z","iopub.status.idle":"2025-07-09T05:35:21.957614Z","shell.execute_reply.started":"2025-07-09T05:35:18.517060Z","shell.execute_reply":"2025-07-09T05:35:21.956822Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"is_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if is_cuda else \"cpu\")\nprint(is_cuda, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:28.403917Z","iopub.execute_input":"2025-07-09T05:35:28.404945Z","iopub.status.idle":"2025-07-09T05:35:28.460419Z","shell.execute_reply.started":"2025-07-09T05:35:28.404916Z","shell.execute_reply":"2025-07-09T05:35:28.459693Z"}},"outputs":[{"name":"stdout","text":"True cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"seed = 827\nrandom.seed(seed)         # python seed\nnp.random.seed(seed)      # numpy seed\ntorch.manual_seed(seed)   # torch seed\nif device == 'cuda':\n  torch.cuda.manual_seed_all(seed)  # gpu seed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:29.409071Z","iopub.execute_input":"2025-07-09T05:35:29.409382Z","iopub.status.idle":"2025-07-09T05:35:29.415397Z","shell.execute_reply.started":"2025-07-09T05:35:29.409357Z","shell.execute_reply":"2025-07-09T05:35:29.414696Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/naver/nlp-challenge/master/missions/ner/data/train/train_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:31.489171Z","iopub.execute_input":"2025-07-09T05:35:31.489454Z","iopub.status.idle":"2025-07-09T05:35:32.223967Z","shell.execute_reply.started":"2025-07-09T05:35:31.489435Z","shell.execute_reply":"2025-07-09T05:35:32.223291Z"}},"outputs":[{"name":"stdout","text":"--2025-07-09 05:35:31--  https://raw.githubusercontent.com/naver/nlp-challenge/master/missions/ner/data/train/train_data\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 16945023 (16M) [application/octet-stream]\nSaving to: ‘train_data’\n\ntrain_data          100%[===================>]  16.16M  --.-KB/s    in 0.1s    \n\n2025-07-09 05:35:32 (145 MB/s) - ‘train_data’ saved [16945023/16945023]\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import os\n\ndef train_iter(file_path=\"train_data\", train=True):\n  sentences = []\n  sentence = [[], [], []]\n  for line in open(file_path, encoding=\"utf-8\"):\n    line = line.strip()\n    if line == \"\":\n      sentences.append(sentence)\n      sentence = [[], [], []]\n    else:\n      idx, ejeol, ner_tag = line.split(\"\\t\")\n      # idx는 0부터 시작하도록\n      sentence[0].append(int(idx))\n      sentence[1].append(ejeol)\n      sentence[2].append(ner_tag)\n  return sentences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:34.177693Z","iopub.execute_input":"2025-07-09T05:35:34.177950Z","iopub.status.idle":"2025-07-09T05:35:34.183575Z","shell.execute_reply.started":"2025-07-09T05:35:34.177927Z","shell.execute_reply":"2025-07-09T05:35:34.182878Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"dl = train_iter()\ndl[3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:35.441527Z","iopub.execute_input":"2025-07-09T05:35:35.441780Z","iopub.status.idle":"2025-07-09T05:35:36.814659Z","shell.execute_reply.started":"2025-07-09T05:35:35.441763Z","shell.execute_reply":"2025-07-09T05:35:36.814087Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n ['7승', '25패는', '상트페테르부르크가', '역대', '월드리그에', '출진한', '분별', '최선의', '성적이다', '.'],\n ['NUM_B', 'NUM_B', 'LOC_B', '-', 'EVT_B', '-', '-', '-', '-', '-']]"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"len(dl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:38.248826Z","iopub.execute_input":"2025-07-09T05:35:38.249364Z","iopub.status.idle":"2025-07-09T05:35:38.253995Z","shell.execute_reply.started":"2025-07-09T05:35:38.249340Z","shell.execute_reply":"2025-07-09T05:35:38.253375Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"90000"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"indices, sentences, labels = zip(*dl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:39.777383Z","iopub.execute_input":"2025-07-09T05:35:39.777649Z","iopub.status.idle":"2025-07-09T05:35:40.027050Z","shell.execute_reply.started":"2025-07-09T05:35:39.777628Z","shell.execute_reply":"2025-07-09T05:35:40.026247Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"print(sentences[0])\nprint(labels[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:41.089772Z","iopub.execute_input":"2025-07-09T05:35:41.090367Z","iopub.status.idle":"2025-07-09T05:35:41.094403Z","shell.execute_reply.started":"2025-07-09T05:35:41.090343Z","shell.execute_reply":"2025-07-09T05:35:41.093685Z"}},"outputs":[{"name":"stdout","text":"['비토리오', '양일', '만에', '영사관', '감호', '용퇴,', '항룡', '압력설', '의심만', '가율']\n['PER_B', 'DAT_B', '-', 'ORG_B', 'CVL_B', '-', '-', '-', '-', '-']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\nspecial_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n\ntext_vocab = build_vocab_from_iterator(sentences,\n                                       min_freq=1,\n                                       specials=special_symbols,\n                                       special_first=True)\ntext_vocab.set_default_index(text_vocab['<unk>'])\n\nner_vocab = build_vocab_from_iterator(labels,\n                                      min_freq=1,\n                                      specials=special_symbols,\n                                      special_first=True)\nner_vocab.set_default_index(text_vocab['<unk>'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:42.969820Z","iopub.execute_input":"2025-07-09T05:35:42.970419Z","iopub.status.idle":"2025-07-09T05:35:44.718140Z","shell.execute_reply.started":"2025-07-09T05:35:42.970395Z","shell.execute_reply":"2025-07-09T05:35:44.717367Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"print(ner_vocab.get_itos())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:46.081396Z","iopub.execute_input":"2025-07-09T05:35:46.082084Z","iopub.status.idle":"2025-07-09T05:35:46.085941Z","shell.execute_reply.started":"2025-07-09T05:35:46.082055Z","shell.execute_reply":"2025-07-09T05:35:46.085169Z"}},"outputs":[{"name":"stdout","text":"['<unk>', '<pad>', '<bos>', '<eos>', '-', 'CVL_B', 'NUM_B', 'PER_B', 'ORG_B', 'DAT_B', 'LOC_B', 'TRM_B', 'EVT_B', 'NUM_I', 'DAT_I', 'ANM_B', 'EVT_I', 'PER_I', 'ORG_I', 'AFW_B', 'CVL_I', 'TRM_I', 'TIM_B', 'FLD_B', 'AFW_I', 'TIM_I', 'PLT_B', 'MAT_B', 'LOC_I', 'ANM_I', 'FLD_I', 'MAT_I', 'PLT_I']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"text_vocab([\"오늘도\", \"빠지지\", \"말고\", \"프로젝트로\", \"시작하는\", \"파이토치\", \"공부하자\",\"!\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T06:11:53.126893Z","iopub.execute_input":"2025-07-09T06:11:53.127601Z","iopub.status.idle":"2025-07-09T06:11:53.132522Z","shell.execute_reply.started":"2025-07-09T06:11:53.127574Z","shell.execute_reply":"2025-07-09T06:11:53.131938Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"[2599, 6351, 1260, 34688, 2807, 0, 0, 30]"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"class NERDataset(Dataset):\n  def __init__(self, file_path=\"train_data\"):\n    sentences = []\n    sentence = [[], []]\n    for line in open(file_path, encoding=\"utf-8\"):\n      line = line.strip()\n      if line == \"\":\n        sentences.append(sentence)\n        sentence = [[], []]\n      else:\n        idx, ejeol, ner_tag = line.split(\"\\t\")\n        sentence[0].append(ejeol)\n        sentence[1].append(ner_tag)\n\n    self.texts, self.labels = zip(*sentences)\n\n  def __getitem__(self, i):\n    return self.texts[i], self.labels[i]\n\n  def __len__(self):\n    return len(self.texts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:48.295601Z","iopub.execute_input":"2025-07-09T05:35:48.296275Z","iopub.status.idle":"2025-07-09T05:35:48.301437Z","shell.execute_reply.started":"2025-07-09T05:35:48.296246Z","shell.execute_reply":"2025-07-09T05:35:48.300672Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"ner_dataset = NERDataset()\nner_dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:49.744425Z","iopub.execute_input":"2025-07-09T05:35:49.745093Z","iopub.status.idle":"2025-07-09T05:35:51.117149Z","shell.execute_reply.started":"2025-07-09T05:35:49.745068Z","shell.execute_reply":"2025-07-09T05:35:51.116407Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(['비토리오', '양일', '만에', '영사관', '감호', '용퇴,', '항룡', '압력설', '의심만', '가율'],\n ['PER_B', 'DAT_B', '-', 'ORG_B', 'CVL_B', '-', '-', '-', '-', '-'])"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"max([len(text) for text in ner_dataset.texts])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:52.096031Z","iopub.execute_input":"2025-07-09T05:35:52.096312Z","iopub.status.idle":"2025-07-09T05:35:52.111002Z","shell.execute_reply.started":"2025-07-09T05:35:52.096290Z","shell.execute_reply":"2025-07-09T05:35:52.110201Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"175"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"def get_dataset(train=0.8, val=0.1, random_seed=827):\n  origin = NERDataset()\n\n  torch.manual_seed(random_seed)\n  trainset, valset, testset = torch.utils.data.random_split(\n    origin,\n    (train, val, 1-train-val),\n  )\n\n  return trainset, valset, testset\n\ntrainset, valset, testset = get_dataset()\nprint(len(trainset), len(valset), len(testset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:53.119666Z","iopub.execute_input":"2025-07-09T05:35:53.119923Z","iopub.status.idle":"2025-07-09T05:35:54.335661Z","shell.execute_reply.started":"2025-07-09T05:35:53.119903Z","shell.execute_reply":"2025-07-09T05:35:54.334797Z"}},"outputs":[{"name":"stdout","text":"72001 9000 8999\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# 순차적인 작업들을 하나로 묶는 헬퍼 함수\ndef sequential_transforms(*transforms):\n    def func(txt_input):\n        for transform in transforms:\n            txt_input = transform(txt_input)\n        return txt_input\n    return func\n\n# BOS/EOS를 추가하고 입력 순서(sequence) 인덱스에 대한 텐서를 생성하는 함수\ndef tensor_transform(token_ids):\n    return torch.cat((torch.tensor([BOS_IDX]),\n                      torch.tensor(token_ids),\n                      torch.tensor([EOS_IDX])))\n\n# 출발어(src)와 도착어(tgt) 원시 문자열들을 텐서 인덱스로 변환하는 변형(transform)\ntext_transforms = sequential_transforms(text_vocab, # 수치화(Numericalization)\n                                        tensor_transform) # BOS/EOS를 추가하고 텐서를 생성\nner_transforms = sequential_transforms(ner_vocab,   # 수치화(Numericalization)\n                                        tensor_transform) # BOS/EOS를 추가하고 텐서를 생성\n\n# 데이터를 텐서로 조합(collate)하는 함수\ndef collate_fn(batch):\n    src_batch, tgt_batch = [], []\n    for src_sample, tgt_sample in batch:\n        src_batch.append(text_transforms(src_sample))\n        tgt_batch.append(ner_transforms(tgt_sample))\n\n    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n    return src_batch, tgt_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:56.104746Z","iopub.execute_input":"2025-07-09T05:35:56.105011Z","iopub.status.idle":"2025-07-09T05:35:56.110795Z","shell.execute_reply.started":"2025-07-09T05:35:56.104990Z","shell.execute_reply":"2025-07-09T05:35:56.110106Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"dataloader = DataLoader(ner_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:35:59.872216Z","iopub.execute_input":"2025-07-09T05:35:59.872495Z","iopub.status.idle":"2025-07-09T05:35:59.884644Z","shell.execute_reply.started":"2025-07-09T05:35:59.872473Z","shell.execute_reply":"2025-07-09T05:35:59.884005Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"for labels, texts in dataloader:\n  print(labels)\n  print(texts)\n  break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:36:00.903993Z","iopub.execute_input":"2025-07-09T05:36:00.904274Z","iopub.status.idle":"2025-07-09T05:36:00.913389Z","shell.execute_reply.started":"2025-07-09T05:36:00.904253Z","shell.execute_reply":"2025-07-09T05:36:00.912700Z"}},"outputs":[{"name":"stdout","text":"tensor([[     2,      2,      2,      2],\n        [ 73762,     10, 124749,  15446],\n        [  8239, 262719,  61435, 115838],\n        [    87,   5261, 119193, 218342],\n        [ 81336,   1030,    296,    388],\n        [ 18246, 111342, 199356,  32484],\n        [256519,      4,  17581,   2418],\n        [ 34887,      3, 108843,  14186],\n        [242483,      1,  49384,   2622],\n        [263591,      1,  25990,  24028],\n        [ 37334,      1, 113884,      4],\n        [     3,      1,     48,      3],\n        [     1,      1, 317094,      1],\n        [     1,      1, 119460,      1],\n        [     1,      1,    131,      1],\n        [     1,      1,      4,      1],\n        [     1,      1,      3,      1]])\ntensor([[ 2,  2,  2,  2],\n        [ 7,  4,  6,  6],\n        [ 9,  4,  4,  6],\n        [ 4,  4,  6, 10],\n        [ 8,  6,  8,  4],\n        [ 5,  6,  7, 12],\n        [ 4,  4,  4,  4],\n        [ 4,  3,  6,  4],\n        [ 4,  1,  4,  4],\n        [ 4,  1,  4,  4],\n        [ 4,  1,  6,  4],\n        [ 3,  1,  4,  3],\n        [ 1,  1,  4,  1],\n        [ 1,  1,  6,  1],\n        [ 1,  1,  4,  1],\n        [ 1,  1,  4,  1],\n        [ 1,  1,  3,  1]])\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# 입력 인덱스의 텐서를 해당하는 토큰 임베딩의 텐서로 변환하기 위한 헬퍼 모듈(Module)\nclass TokenEmbedding(nn.Module):\n    def __init__(self, vocab_size: int, emb_size):\n        super(TokenEmbedding, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_size)\n        self.emb_size = emb_size\n\n    def forward(self, tokens):\n        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:36:02.824964Z","iopub.execute_input":"2025-07-09T05:36:02.825640Z","iopub.status.idle":"2025-07-09T05:36:02.829966Z","shell.execute_reply.started":"2025-07-09T05:36:02.825616Z","shell.execute_reply":"2025-07-09T05:36:02.829273Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"seq_len = 10\nbatch_size = 4\nvocab_size = 10\nemb_size = 32\nemb = TokenEmbedding(vocab_size, emb_size)\n\nsample = torch.randint(0, vocab_size, (seq_len, batch_size))\nprint(sample)\nprint(emb(sample).shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:36:34.902009Z","iopub.execute_input":"2025-07-09T05:36:34.902635Z","iopub.status.idle":"2025-07-09T05:36:34.908735Z","shell.execute_reply.started":"2025-07-09T05:36:34.902610Z","shell.execute_reply":"2025-07-09T05:36:34.908036Z"}},"outputs":[{"name":"stdout","text":"tensor([[0, 0, 1, 1],\n        [8, 7, 1, 6],\n        [1, 8, 2, 4],\n        [2, 8, 7, 9],\n        [8, 4, 0, 3],\n        [0, 9, 2, 1],\n        [6, 4, 4, 0],\n        [3, 9, 7, 3],\n        [8, 8, 4, 1],\n        [0, 2, 4, 2]])\ntorch.Size([10, 4, 32])\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# 단어 순서 개념(notion)을 토큰 임베딩에 도입하기 위한 위치 인코딩(positional encoding)을 위한 헬퍼 모듈(Module)\nclass PositionalEncoding(nn.Module):\n  def __init__(self, emb_size, dropout, maxlen=5000):\n    super(PositionalEncoding, self).__init__()\n    den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n    pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n\n    pos_embedding = torch.zeros((maxlen, emb_size))\n    pos_embedding[:, 0::2] = torch.sin(pos * den)\n    pos_embedding[:, 1::2] = torch.cos(pos * den)\n    pos_embedding = pos_embedding.unsqueeze(-2)\n\n    self.dropout = nn.Dropout(dropout)\n    self.register_buffer('pos_embedding', pos_embedding)\n\n  def forward(self, token_embedding):\n    token_embedding += self.pos_embedding[:token_embedding.size(0), :]\n    return self.dropout(token_embedding)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:36:38.073473Z","iopub.execute_input":"2025-07-09T05:36:38.073936Z","iopub.status.idle":"2025-07-09T05:36:38.079683Z","shell.execute_reply.started":"2025-07-09T05:36:38.073909Z","shell.execute_reply":"2025-07-09T05:36:38.078918Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"seq_len, batch_size, emb_size, dropout = 10, 4, 32, 0.1\npe = PositionalEncoding(emb_size, dropout)\n\nsample = torch.rand((seq_len, batch_size, emb_size))\nx = pe(sample).shape\nprint(\"PE:    \", pe.pos_embedding[:sample.size(0), :].shape)\nprint(\"RESULT:\", x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:36:40.264878Z","iopub.execute_input":"2025-07-09T05:36:40.265171Z","iopub.status.idle":"2025-07-09T05:36:40.289834Z","shell.execute_reply.started":"2025-07-09T05:36:40.265135Z","shell.execute_reply":"2025-07-09T05:36:40.289207Z"}},"outputs":[{"name":"stdout","text":"PE:     torch.Size([10, 1, 32])\nRESULT: torch.Size([10, 4, 32])\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Seq2Seq 신경망\nclass Seq2SeqTransformer(nn.Module):\n    def __init__(self,\n                num_encoder_layers: int,\n                num_decoder_layers: int,\n                emb_size: int,\n                nhead: int,\n                src_vocab_size: int,\n                tgt_vocab_size: int,\n                dim_feedforward: int = 512,\n                dropout: float = 0.1):\n        super(Seq2SeqTransformer, self).__init__()\n        self.transformer = nn.Transformer(d_model=emb_size,\n                                        nhead=nhead,\n                                        num_encoder_layers=num_encoder_layers,\n                                        num_decoder_layers=num_decoder_layers,\n                                        dim_feedforward=dim_feedforward,\n                                        dropout=dropout)\n        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n        self.positional_encoding = PositionalEncoding(\n            emb_size, dropout=dropout)\n\n    def forward(self,\n                src,\n                trg,\n                src_mask,\n                tgt_mask,\n                src_padding_mask,\n                tgt_padding_mask,\n                memory_key_padding_mask):\n      src_emb = self.positional_encoding(self.src_tok_emb(src))\n      tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n      outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n                              src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n      return self.generator(outs)\n    \n    def encode(self, src, src_mask):\n      return self.transformer.encoder(self.positional_encoding(\n                          self.src_tok_emb(src)), src_mask)\n    \n    def decode(self, tgt, memory, tgt_mask):\n      return self.transformer.decoder(self.positional_encoding(\n                        self.tgt_tok_emb(tgt)), memory,\n                        tgt_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:36:43.161870Z","iopub.execute_input":"2025-07-09T05:36:43.162138Z","iopub.status.idle":"2025-07-09T05:36:43.178143Z","shell.execute_reply.started":"2025-07-09T05:36:43.162117Z","shell.execute_reply":"2025-07-09T05:36:43.177439Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def generate_square_subsequent_mask(sz):\n  mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n  mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n  return mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:36:45.393040Z","iopub.execute_input":"2025-07-09T05:36:45.393341Z","iopub.status.idle":"2025-07-09T05:36:45.397648Z","shell.execute_reply.started":"2025-07-09T05:36:45.393320Z","shell.execute_reply":"2025-07-09T05:36:45.397019Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"generate_square_subsequent_mask(4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:36:46.632183Z","iopub.execute_input":"2025-07-09T05:36:46.632464Z","iopub.status.idle":"2025-07-09T05:36:47.635218Z","shell.execute_reply.started":"2025-07-09T05:36:46.632443Z","shell.execute_reply":"2025-07-09T05:36:47.634530Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"tensor([[0., -inf, -inf, -inf],\n        [0., 0., -inf, -inf],\n        [0., 0., 0., -inf],\n        [0., 0., 0., 0.]], device='cuda:0')"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"def create_mask(src, tgt):\n  src_seq_len = src.shape[0]\n  tgt_seq_len = tgt.shape[0]\n\n  tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n  src_mask = torch.zeros((src_seq_len, src_seq_len),device=device).type(torch.bool)\n\n  src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n  tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n  return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:36:48.080849Z","iopub.execute_input":"2025-07-09T05:36:48.081106Z","iopub.status.idle":"2025-07-09T05:36:48.085724Z","shell.execute_reply.started":"2025-07-09T05:36:48.081086Z","shell.execute_reply":"2025-07-09T05:36:48.085156Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"src = torch.Tensor([[5], [5], [5], [1], [1]])\ntgt = torch.Tensor([[5], [5], [1], [1], [1]])\ncreate_mask(src, tgt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:36:49.352078Z","iopub.execute_input":"2025-07-09T05:36:49.352377Z","iopub.status.idle":"2025-07-09T05:36:49.360901Z","shell.execute_reply.started":"2025-07-09T05:36:49.352352Z","shell.execute_reply":"2025-07-09T05:36:49.360286Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"(tensor([[False, False, False, False, False],\n         [False, False, False, False, False],\n         [False, False, False, False, False],\n         [False, False, False, False, False],\n         [False, False, False, False, False]], device='cuda:0'),\n tensor([[0., -inf, -inf, -inf, -inf],\n         [0., 0., -inf, -inf, -inf],\n         [0., 0., 0., -inf, -inf],\n         [0., 0., 0., 0., -inf],\n         [0., 0., 0., 0., 0.]], device='cuda:0'),\n tensor([[False, False, False,  True,  True]]),\n tensor([[False, False,  True,  True,  True]]))"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"def train(model, dataloader, criterion, optimizer, epoch, device):\n  model.train()\n\n  running_loss = 0\n  correct = 0\n\n  with tqdm(dataloader) as pbar:\n    pbar.set_description(f'Epoch - {epoch} TRAIN')\n    for i, (data, targets) in enumerate(pbar):\n      data, targets = data.to(device), targets.to(device)\n\n      tgt_input = targets[:-1, :]\n\n      src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(data, tgt_input)\n\n      logits = model(data, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n\n      optimizer.zero_grad()\n      tgt_out = targets[1:, :]\n      loss = criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n      torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n      loss.backward()\n      optimizer.step()\n\n      running_loss += loss.item()\n      pbar.set_postfix(loss=loss.item())\n\n    data_num = len(dataloader.dataset)\n    acc = 100. * correct / data_num\n\n    final_loss = running_loss/len(dataloader)\n    pbar.set_postfix(loss=final_loss)\n\n  return final_loss, acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:36:50.935844Z","iopub.execute_input":"2025-07-09T05:36:50.936079Z","iopub.status.idle":"2025-07-09T05:36:50.942531Z","shell.execute_reply.started":"2025-07-09T05:36:50.936062Z","shell.execute_reply":"2025-07-09T05:36:50.941904Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def validation(model, dataloader, criterion, epoch, device):\n  model.eval()\n\n  correct = 0\n  running_loss = 0.\n\n  with tqdm(dataloader) as pbar:\n    pbar.set_description(f'Epoch - {epoch} VALID')\n    with torch.no_grad():\n      for i, (data, targets) in enumerate(pbar):\n        data, targets = data.to(device), targets.to(device)\n\n        tgt_input = targets[:-1, :]\n        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(data, tgt_input)\n\n        logits = model(data, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n\n        tgt_out = targets[1:, :]\n        loss = criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n\n        running_loss += loss.item()\n        pbar.set_postfix(loss=loss.item())\n\n  data_num = len(dataloader.dataset)\n  acc = 100. * correct / data_num\n\n  final_loss = running_loss/len(dataloader)\n  pbar.set_postfix(loss=final_loss)\n\n  return final_loss, acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:36:53.344479Z","iopub.execute_input":"2025-07-09T05:36:53.344726Z","iopub.status.idle":"2025-07-09T05:36:53.351101Z","shell.execute_reply.started":"2025-07-09T05:36:53.344710Z","shell.execute_reply":"2025-07-09T05:36:53.350456Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"EPOCH = 7\nBATCH_SIZE = 64\nNUM_WORKERS = 1\nLR = 0.0001\n\ntrainset, valset, testset = get_dataset()\n\n# dataloader\ntrain_loader = DataLoader(\n  dataset=trainset,\n  shuffle=True,\n  batch_size=BATCH_SIZE,\n  num_workers=NUM_WORKERS,\n  collate_fn=collate_fn\n)\nval_loader = DataLoader(\n  dataset=valset,\n  batch_size=BATCH_SIZE,\n  num_workers=NUM_WORKERS,\n  collate_fn=collate_fn\n)\ntest_loader = DataLoader(\n  dataset=testset,\n  batch_size=BATCH_SIZE,\n  num_workers=NUM_WORKERS,\n  collate_fn=collate_fn\n)\n\n# model\nNUM_ENCODER_LAYERS = 3\nNUM_DECODER_LAYERS = 3\nEMB_SIZE = 512\nNHEAD = 8\nSRC_VOCAB_SIZE = len(text_vocab)\nTGT_VOCAB_SIZE = len(ner_vocab)\nFFN_HID_DIM = 512\nDROPOUT = 0.2\n\nmodel = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n                           NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM, DROPOUT)\n\nfor p in model.parameters():\n    if p.dim() > 1:\n        nn.init.xavier_uniform_(p)\n\n# Optimizer, Loss, Scheduler\ncriterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR, betas=(0.9, 0.98), eps=1e-9)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n\nmodel = model.to(device)\ncriterion = criterion.to(device)\n\nmin_loss = 999\n# Start Training\nfor epoch in range(EPOCH):\n  print(\"LR:\", scheduler.get_last_lr())\n\n  start_time = timer()\n  tloss, tacc = train(model, train_loader, criterion, optimizer, epoch, device)\n  end_time = timer()\n\n  start_time = timer()\n  vloss, vacc = validation(model, val_loader, criterion, epoch, device)\n  end_time = timer()\n\n  scheduler.step()\n\n  if vloss < min_loss:\n    min_loss = vloss\n    torch.save(model.state_dict(), \"best.pth\")\n    print(\"save model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:36:55.368616Z","iopub.execute_input":"2025-07-09T05:36:55.369264Z","iopub.status.idle":"2025-07-09T05:55:36.684033Z","shell.execute_reply.started":"2025-07-09T05:36:55.369218Z","shell.execute_reply":"2025-07-09T05:55:36.683308Z"}},"outputs":[{"name":"stdout","text":"LR: [0.0001]\n","output_type":"stream"},{"name":"stderr","text":"Epoch - 0 TRAIN: 100%|██████████| 1126/1126 [02:34<00:00,  7.29it/s, loss=0.961]\nEpoch - 0 VALID: 100%|██████████| 141/141 [00:03<00:00, 40.25it/s, loss=1.1]  \n","output_type":"stream"},{"name":"stdout","text":"save model\nLR: [9.5e-05]\n","output_type":"stream"},{"name":"stderr","text":"Epoch - 1 TRAIN: 100%|██████████| 1126/1126 [02:34<00:00,  7.27it/s, loss=0.305]\nEpoch - 1 VALID: 100%|██████████| 141/141 [00:03<00:00, 40.33it/s, loss=0.881]\n","output_type":"stream"},{"name":"stdout","text":"save model\nLR: [9.025e-05]\n","output_type":"stream"},{"name":"stderr","text":"Epoch - 2 TRAIN: 100%|██████████| 1126/1126 [02:35<00:00,  7.26it/s, loss=0.564]\nEpoch - 2 VALID: 100%|██████████| 141/141 [00:03<00:00, 40.29it/s, loss=0.762]\n","output_type":"stream"},{"name":"stdout","text":"save model\nLR: [8.573749999999999e-05]\n","output_type":"stream"},{"name":"stderr","text":"Epoch - 3 TRAIN: 100%|██████████| 1126/1126 [02:35<00:00,  7.26it/s, loss=1.03] \nEpoch - 3 VALID: 100%|██████████| 141/141 [00:03<00:00, 40.48it/s, loss=0.708]\n","output_type":"stream"},{"name":"stdout","text":"save model\nLR: [8.145062499999998e-05]\n","output_type":"stream"},{"name":"stderr","text":"Epoch - 4 TRAIN: 100%|██████████| 1126/1126 [02:35<00:00,  7.26it/s, loss=0.522]\nEpoch - 4 VALID: 100%|██████████| 141/141 [00:03<00:00, 40.28it/s, loss=0.779]\n","output_type":"stream"},{"name":"stdout","text":"LR: [7.737809374999998e-05]\n","output_type":"stream"},{"name":"stderr","text":"Epoch - 5 TRAIN: 100%|██████████| 1126/1126 [02:35<00:00,  7.26it/s, loss=0.0241]\nEpoch - 5 VALID: 100%|██████████| 141/141 [00:03<00:00, 40.14it/s, loss=0.776]\n","output_type":"stream"},{"name":"stdout","text":"LR: [7.350918906249998e-05]\n","output_type":"stream"},{"name":"stderr","text":"Epoch - 6 TRAIN: 100%|██████████| 1126/1126 [02:35<00:00,  7.26it/s, loss=0.209] \nEpoch - 6 VALID: 100%|██████████| 141/141 [00:03<00:00, 40.23it/s, loss=0.772]\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"def greedy_decode(model, src, src_mask, max_len, start_symbol):\n  src = src.to(device)\n  src_mask = src_mask.to(device)\n\n  memory = model.encode(src, src_mask)\n  ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n\n  for i in range(max_len-1):\n    memory = memory.to(device)\n    tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n                .type(torch.bool)).to(device)\n    out = model.decode(ys, memory, tgt_mask)\n    out = out.transpose(0, 1)\n    prob = model.generator(out[:, -1])\n    _, next_word = torch.max(prob, dim=1)\n    next_word = next_word.item()\n\n    ys = torch.cat([ys,\n                    torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n    if next_word == EOS_IDX:\n      break\n  return ys\n\ndef translate(model: torch.nn.Module, src_sentence: str):\n  model.eval()\n  src = text_transforms(src_sentence).view(-1, 1)\n  num_tokens = src.shape[0]\n  src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n  tgt_tokens = greedy_decode(\n    model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n  return \" \".join(\n      ner_vocab.lookup_tokens(list(tgt_tokens.cpu().numpy()))\n    ).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T05:56:21.833629Z","iopub.execute_input":"2025-07-09T05:56:21.834111Z","iopub.status.idle":"2025-07-09T05:56:21.841152Z","shell.execute_reply.started":"2025-07-09T05:56:21.834089Z","shell.execute_reply":"2025-07-09T05:56:21.840438Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"best.pth\"))\ntokenizer = get_tokenizer(\"spacy\", \"ko_core_news_sm\")\nprint(translate(model, tokenizer(\"12월 25일 부산에서 아시안게임 개최 논의\")))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T06:10:14.767657Z","iopub.execute_input":"2025-07-09T06:10:14.768190Z","iopub.status.idle":"2025-07-09T06:10:16.370509Z","shell.execute_reply.started":"2025-07-09T06:10:14.768169Z","shell.execute_reply":"2025-07-09T06:10:16.369771Z"}},"outputs":[{"name":"stdout","text":" DAT_B LOC_B LOC_B EVT_B EVT_I - \n","output_type":"stream"}],"execution_count":54}]}